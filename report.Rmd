---
title: "Subway Crime Analysis"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

<link rel="stylesheet" href="academicons.css"/>
<link rel="stylesheet" href="styles.css" type="text/css">

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(RColorBrewer)
library(data.table)
library(readxl)
library(rvest)
library(leaflet)
library(httr)
library(lubridate)
library(plotly)
library(tigris) 
##install.packages("leaflet.extras")
library(leaflet.extras)
set.seed(77)


knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = 1,
  out.width = "98%"
)

theme_set(theme_minimal() + theme(legend.position = 'bottom'))

options(
  ggplot2.continuous.colour = 'viridis',
  ggplot2.continuous.fill = 'viridis'
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d


```


# Introduction

New York subway, one of the main public transportations for New Yorkers, provides super convenience for local citizens, at the same time, brings potential danger to passengers, where criminals are attracted to busier subway stations for certain kinds of crime like pickpocketing, grand larceny, and assault. This closest place will trigger evil. 

<center>

![Wordcloud using victims description](images/Word_Cloud.png){width=75%}

</center>

On November 21, around 12:00 AM, at 34th Street-Penn Station in Manhattan, Alkeem Loney, a 32-year-old male, was stabbed in the neck during an unprovoked attack and was pronounced dead later as NYPD stated. The deadly incident is the latest in a pate of violence underground that comes as the MTA tries to get commuters back on mass transit. The horrible crime event raised lots of public concern about the safety at subway stations, the safety is tightly related to almost every citizen who is living, working, and studying in New York City. 

As students who are living here in New York City, most of us will almost take the subway to the campus in the early morning and back to the apartment in the night on weekdays, and hang out with friends on weekends. However, some of my friends experienced uncompleted crimes. Keeping away from danger at subway stations is closely related to ourselves. We hope we are able to help citizens to find comparatively safe and reliable routes when taking subways.

# Data


## Data Introduction

### Subway Crime

The orginal subway crime data has two parts.[The first one ](https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Current-Year-To-Date-/5uac-w243) contains all valid felony, misdemeanor, and violation crimes reported to the New York City Police Department--- [NYPD](https://www1.nyc.gov/site/nypd/index.page). The [second one](https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i)  includes similar crimes. We join these two data frames and only analyze crimes which happen in subway, NYC.  

The variables we use are(some useless variable's meaning can be found in the link above):

``` {r, include=FALSE}
variable_crime<-read_excel("data/variable explaination.xls")
```

`r variable_crime %>% knitr::kable()`

### Subway Passenger

The orginal [Subway passenger data](http://web.mta.info/developers/turnstile.html) is from [MTA](https://new.mta.info/)(Metropolitan Transportation Authority). The orginal data contains total entries and exits in each station in every 4 hours from 2010 to now. Data is not in a readable format, they are seperated by time in different htmls, we read and process passenger data with [ GenerateSubwayPassengerData.rmd](https://github.com/zheyanliu99/SubwayCrime/blob/main/data/GenerateSubwayPassengerData2.Rmd)

The variables we use are:


| colum name | description                                                            | type      |   |   |
|------------|------------------------------------------------------------------------|-----------|---|---|
| STATION    | station name                                                           | Character |   |   |
| LINENAME   | lines in this station, there can be more than one lines in one station | Character |   |   |
| DATE       | format MM/DD/YYYY                                                      | Date      |   |   |
| TIME       | format HH:MM:SS                                                        | Date      |   |   |
| ENTRIES    | cumulative entries                                                     | Intergar  |   |   |
| EXITS      | cumulative exits                                                       | Intergar  |   |   |


## Data Cleanning

### Subway Crime

#### the Least Distance
In order to compare crime and subway passengers' data, we find that we need to transfer to the same subway line and station name.(Different stations have different abbreviation.)</br>
We use the crime data's latitude and longitude to match the subway's data. The station in the subway information closet to the each row of crime data will be matched. (which has information about all the station's name, line and location.) </br>
Some crime data who have deviant longitude and latitude will be excluded. 

### Subway Passenger

#### K-Means

We set the number of clusters to be 8 and use Kmeans to cluster latitudes and longitudes. After K-means we have 8 clusters of locations instead of the original 4 boro, making it closer to reality (for instance we have lower, middle and upper Manhatten in the clusters)and better for model classification. The kmeans code is in [PassengerEDA.Rmd](https://github.com/zheyanliu99/SubwayCrime/blob/main/PassengerEDA.Rmd)

#### Imputation

Some missing data from passenger's exit and enter count, we use mean of former values to impute them. The imputation code we use is [FutherCleanPassenger.py](https://github.com/zheyanliu99/SubwayCrime/blob/main/data/FutherCleanPassenger.py)

#### Google Map Api to find station coordinates

We want to get coordinates of each station for the following reasons

* location-based data visualization and analysis
* More location-based features for the model
* The station name in crime and passenger data are not matched, we can use corrdinates to match them

However, how to get the correct coordinates is tricky, there are open datas about NYC subway stations infomation and all of them have different naming system with ours. In addition, the station names contain lots of dupilicates. For instance, there are 2 86 st stations in middle Manhattan and another one in Brooklyn. We can get the correct coordinates of stations by using both station names and line names. Therefore, our solution is to use [Google Maps Api](https://developers.google.com/maps). The code we use is [Subway_info.py](https://github.com/zheyanliu99/SubwayCrime/blob/main/data/Subway_info.py)

#### Add service column

There are too many subway lines and some of them share most of the rails, therefore it is not reasonable to conduct analysis or building models with the line name. Therefore, we created a new variable called service based on the defination of MTA. For instance, line A, B and C are called 
'8 Avenue'.
<br>
<center>

![](images/SubwayMap.jpg){width=60%}

</center>
<br>



#### Correct subway line
According to the New York City Subway instruction, there are several different transfer between lines. The first is the inside transfer, where you can transfer from one line to other line inside the station. For example, 14 St-Union Sq is a  station of Line LNQRW456. We don't need to some adjustment for these stations. 
The second one is free subway transfer and free out-of-way-system. This transfer is different from the inside transfer, passengers need to move from one station to other station for transfer. The data of these transfers has some problems. For example, there are free subway transfer between Court ST-23 ST(EM) and Court Sq(G7). However, the dataset shows the station and line is Court ST-23 ST:EGM, Court Sq:EGM, Court Sq:7. To deal with problem like this, we reassigned the line of station with free subway transfer or free out-of-way-system according to the New York City Subway instruction. In this case, we only consider the insider transfer station.


#### Outliers of entries and exits

For each station and given time, We got the actual entries and exits by calculating the difference of cumulative entries and exits between current time and last time. However, final results contains some outliers, some entries and exits are negative or extremely large. For these outliers, we replaced them with the mean of last two observations at the same time and station. We did this by  [FutherCleanPassenger.py](https://github.com/zheyanliu99/SubwayCrime/blob/main/data/FutherCleanPassenger.py).


# Exploratory Data Analysis

We conduct EDA to find the trends of data and provide insights for model. In the first section, we analyze subway crime data and produce an [interactive Shiny Dashboard](https://stephenyuan.shinyapps.io/CrimeMapShiny/) about subway crime, people can look up crime rate in each location, distribution of each crime type. For the other one, we analyze passenger data and create a new variable *cluster* using Kmeans. Additionally, we build a shiny app for [Subway passenger flow animation and info lookup](https://chaoqiwu0324.shinyapps.io/subway_passenger/) and a more detailed app on each [line](https://chaoqiwu0324.shinyapps.io/line_passenger/)

```{r read,include=FALSE}

crime_df = read_csv('data/subwaycrime_with_station_new.csv')

crime_df<-crime_df %>% 
 mutate(cmplnt_to_dt=as.Date(cmplnt_to_dt,format='%m/%d/%Y')) %>% 
 filter(distance<=0.0001)%>% 
 filter(cmplnt_to_dt>='2006-1-1')

```

## Subway Crime

New York City can be a dangerous place and crime from above ground will 
often extend into the NYC Subway. We mainly focus on the recent crime data on subway in NYC in this year, and 
there are `r nrow(crime_df)` complaints from 2006 to now. 

### Crime by Location




#### Heat Map of Subway Crime in NYC, 2006-2021

From this map, you can check where the crime happened frequently. 
```{r heatmap, echo = FALSE, message=FALSE, warning=FALSE}
crime_df %>% 
  group_by(closest_station) %>% 
  summarise(Trend=n(),
            longitude=mean(longitude),
            latitude=mean(latitude)) %>% 
  leaflet() %>% 
  addTiles() %>% 
  addHeatmap(lng=~longitude,lat=~latitude,
             intensity=~exp(Trend),max=100,radius=5,blur=10)

```

#### Map of Subway Crime in NYC, 2006-2021

From this map, you can check each crime's location, type, victim and suspects' 
information and time. 

```{r leaflet, echo = FALSE, message=FALSE, warning=FALSE}



leaflet(crime_df) %>%
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addMarkers(lat = ~latitude, lng = ~longitude, 
             popup = paste("Offense Description:", crime_df$ofns_desc, "<br>",
                           "Suspect's age:",crime_df$susp_age_group,"<br>",
                           "Suspect's race:", crime_df$susp_race,"<br>",
                           "Suspect's gender:",crime_df$susp_sex,"<br>",
                           "Victim's age:",crime_df$vic_age_group,"<br>",
                           "Victim's race:", crime_df$vic_race,"<br>",
                           "Victim's gender:",crime_df$vic_sex,"<br>",
                           "Time:",crime_df$cmplnt_to_dt),
                clusterOptions = markerClusterOptions())
  


### "Offense Description:", crime_df$ofns_desc, "<br>",
### "<br>", 
###                 
###                 "Suspect Information", c(crime_df$susp_age_group,
###                                          crime_df$susp_race,
###                                          crime_df$susp_sex), "<br>",
###                 "Victim Information:", c(crime_df$vic_age_group,
###                                          crime_df$vic_race,
###                                          crime_df$vic_sex), 
```

#### Distribution of crime in 7 Clusters

When firstly scanning the map above, you can ambiguously know how many crimes 
in each part of NYC, so let us check them in each ambiguously using bar chart.

```{r barcluster, echo = FALSE, message=FALSE, warning=FALSE}

crime_df %>% 
  count(cluster) %>% 
  mutate(cluster = fct_reorder(cluster, n)) %>% 
  slice_max(n,n=20) %>% 
  plot_ly(x = ~cluster, y = ~n, color = ~cluster, type = "bar", colors = "viridis") %>% 
  layout(yaxis = list(title = 'Number of Compliants'),
         xaxis = list(title = 'Cluster'))
```

#### Top 10 offense classification


There are `r count(distinct(crime_df,ofns_desc))` kinds of crime occurring in the subway, there is the bar chart shows the wildest 10 crimes in the subway.

The most frequent crime mainly consists of grand larceny and assaults.

```{r offense, echo = FALSE, message=FALSE, warning=FALSE}

crime_df %>% 
  count(ofns_desc) %>% 
  mutate(ofns_desc = fct_reorder(ofns_desc, n)) %>% 
  slice_max(n,n=10) %>% 
  plot_ly(x = ~ofns_desc, y = ~n, color = ~ofns_desc, type = "bar", colors = "viridis") %>% 
  layout(yaxis = list(title = 'Number of Compliants'),
         xaxis = list(title = 'Type of Offense'))

#### some data's resources
#### https://stackoverflow.com/questions/51955803/how-to-change-x-axis-layout-using-plotly-in-r

```

#### Top 20 station where crime happens frequently

From this chart, you can mainly check which station is the most dangerous station.
```{r station, echo = FALSE, message=FALSE, warning=FALSE}

crime_df %>% 
  count(closest_station) %>% 
  mutate(closest_station = fct_reorder(closest_station, n)) %>% 
  slice_max(n,n=20) %>% 
  plot_ly(x = ~closest_station, y = ~n, color = ~closest_station, type = "bar", colors = "viridis") %>% 
  layout(yaxis = list(title = 'Number of Compliants'),
         xaxis = list(title = 'Type of station'))


```




```{r suprace, echo = FALSE, message=FALSE, warning=FALSE}
### 
### crime_df %>% 
###   drop_na(cluster,susp_race) %>% 
###   filter(susp_race!="UNKNOWN") %>% 
###   count(cluster,susp_race) %>% 
###   mutate(cluster = fct_reorder(cluster, n)) %>% 
###   plot_ly(x = ~cluster, y = ~n, color = ~susp_race, type = "bar", colors = "viridis") %>% 
###   layout(
###          yaxis = list(title = 'Number of Compliants'),
###          xaxis = list(title = 'Area'))

```

#### Barchart by each Borough about Victims

From this graph, you can check in each borough, which races more possibly 
vulnerable in the subway. 

As you can see, the proportion of African Americans in each cluster are stable; In Manhattan, where has the most crimes, white people(including white hispanic) are more vunlerable than African Americans in these places. 
```{r vicrace, echo = FALSE, message=FALSE, warning=FALSE}
crime_df %>%
  filter(vic_race!="UNKNOWN") %>%
  count(cluster,vic_race) %>%
  mutate(cluster = fct_reorder(cluster, n)) %>% 
  plot_ly(x = ~cluster, y = ~n, color = ~vic_race, type = "bar", colors = "viridis") %>%
  layout(
         yaxis = list(title = 'Number of Compliants'),
         xaxis = list(title = 'Cluster'))

```


#### Gender Distrubution for popular crime types

In this part, we want to know which gender are more possible to become potential victims. We choose several types of crime from the most frequent kinds of crimes:</br>
ASSAULT 3 & RELATED OFFENSES,HARRASSMENT 2,GRAND LARCENY,FELONY ASSAULT,
ROBBERY,PETIT LARCENY,SEX CRIMES.</br>
We can find that crimes about sex crimes and harassment, female are more possible to be attacked. Crimes about regular theft, such as assault and larceny, male are potential victims comparing with female. 

```{r gender, echo = FALSE, message=FALSE, warning=FALSE}
crime_df %>% 
  filter(ofns_desc %in% c("ASSAULT 3 & RELATED OFFENSES",
                          "HARRASSMENT 2","GRAND LARCENY",
                          "FELONY ASSAULT",
                          "ROBBERY","PETIT LARCENY",
                          "SEX CRIMES")
  ) %>% 
  filter(vic_sex %in% c("F","M")) %>% 
  count(ofns_desc,vic_sex) %>% 
  mutate(ofns_desc = fct_reorder(ofns_desc, n)) %>% 
  plot_ly(x = ~ofns_desc, y = ~n, color = ~vic_sex, type = "bar", colors = "viridis") %>% 
  layout(
         yaxis = list(title = 'Number of Compliants'),
         xaxis = list(title = 'Age Group'))
  
                

```


#### Female Age Distribution for Sex Crimes 

Let us talk more about age group for some specific crimes: SEX CRIMES and HARRASSMENT 2. </br>
Most of the victims' age are in the age 25-44 interval. 



```{r harrass, echo = FALSE, message=FALSE, warning=FALSE}
crime_df %>% 
  filter(ofns_desc %in% c("SEX CRIMES","HARRASSMENT 2")) %>% 
  count(vic_age_group,vic_race) %>% 
  filter(vic_age_group!="-59") %>% 
  filter(vic_age_group!="UNKNOWN") %>%
  filter(vic_race!="UNKNOWN") %>%
  plot_ly(x = ~vic_age_group, y = ~n, color = ~vic_race, type = "bar", colors = "viridis") %>% 
  layout(
         yaxis = list(title = 'Number of Compliants'),
         xaxis = list(title = 'Age Group-Female'))
  
```

#### Crimr Rate Top 20
Sometimes, we more care about the crime rates on subway rather than number of crimes, because we also care the possiblity that the people standing in front of us is suspective. 
```{r crime_rate, echo = FALSE, message=FALSE, warning=FALSE}
crime_rate_summary<-read.csv("data/crime_rate_station.csv")
crime_rate_summary %>% 
  mutate(crime=n) %>% 
  select(-n) %>% 
  relocate(linename,station,flow,crime) %>% 
  slice_max(crime_rate,n=20) %>%
  knitr::kable()
  
```



### Crime by Time

We already had a general picture about stations that are comparably dangerous, and types of crime events that happened frequently in last several years.

Now Let's dig into the relationship between **time** and the occurrence of various **crime events**.

In the next few plots, we may try to explore questions like...

* Which year is along with the highest frequency of various crime events? 

* Which season is along with the highest frequency of various crime events? 

* Which time points in a day are along with more crime events? 

```{r, include = FALSE, echo = FALSE, message=FALSE, warning=FALSE}
raw_sub_crime = 
  read_csv("data/subwaycrime_with_station_new_1.csv") %>% 
  janitor::clean_names() %>% 
  rename("start_date" = "cmplnt_fr_dt", "start_time" = "cmplnt_fr_tm", "end_date" = "cmplnt_to_dt", "end_time" = "cmplnt_to_tm", "law_cat" = "law_cat_cd", "crime_event" = "ofns_desc", "crime_desc" = "pd_desc") %>% 
  mutate(law_cat = ordered(law_cat, level = c("VIOLATION", "MISDEMEANOR", "FELONY"))) %>% 
  mutate(start_date = as.Date(start_date, "%m/%d/%Y"), 
         end_date = as.Date(end_date, "%m/%d/%Y")) %>% 
  mutate(start = as.POSIXct(paste(start_date, start_time), format = "%Y-%m-%d %H:%M:%S"), 
         end = as.POSIXct(paste(end_date, end_time), format = "%Y-%m-%d %H:%M:%S")) %>% 
  mutate(crime_event = tolower(crime_event),
         law_cat = tolower(law_cat),
         crime_desc = tolower(crime_desc)) %>% 
  drop_na(start_time) %>% 
  separate(start_time, into = c("start_time_hour", "event_minute", "event_second"), sep = ":") %>% 
  select(start_date, start_time_hour, end_date, end_time, law_cat, crime_event, crime_desc, start, end) %>% 
  filter(start_date > "2005-12-31")
```

#### Number of events each year

```{r, message=FALSE, warning=FALSE}
sub_crime_year = 
  raw_sub_crime %>% 
  select(start_date, start_time_hour, crime_event, law_cat) %>% 
  mutate(start_date = substring(start_date, 1, 4))

plot_1 = 
  sub_crime_year %>% 
  group_by(start_date) %>% 
  summarise(event_num = n() / 1000) %>% 
  plot_ly(
    x = ~start_date, y = ~event_num, type = "bar"
  )

layout(plot_1, title = "Crime events over years", xaxis = list(title = "Year"), yaxis = list(title = "Number of Crime Events (K)"))
```

#### Number of events each quarter

```{r, message=FALSE, warning=FALSE}
sub_crime_season = 
  raw_sub_crime %>% 
  select(start_date, start_time_hour, crime_event, law_cat) %>% 
  separate(start_date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(season = case_when(
    month %in% c("01","02","03") ~ "Q1",
    month %in% c("04","05","06") ~ "Q2",
    month %in% c("07","08","09") ~ "Q3",
    month %in% c("10","11","12") ~ "Q4"
  )) %>% 
  mutate(event_quarter = paste(year, season, sep = "-"))
  
plot_2 = 
  sub_crime_season %>% 
  group_by(event_quarter) %>% 
  summarise(event_num = n()) %>% 
  plot_ly(
    x = ~event_quarter, y = ~event_num, type = "scatter", mode = "points"
  )

layout(plot_2, title = "Crime events over quarter", xaxis = list(title = "Quarter"), yaxis = list(title = "Number of Crime Events"), width = 800)
```

#### Number of events each month

```{r, message=FALSE, warning=FALSE}
sub_crime_month = 
  raw_sub_crime %>% 
  select(start_date, start_time_hour, crime_event, law_cat) %>% 
  separate(start_date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(month = ifelse(month == "01", "January", ifelse(month == "02", "February", ifelse(month == "03", "March", ifelse(month == "04", "April", ifelse(month == "05", "May", ifelse(month == "06", "June", ifelse(month == "07", "July", ifelse(month == "08", "August", ifelse(month == "09", "September", ifelse(month == "10", "October", ifelse(month == "11", "November", "December")))))))))))) %>% 
  mutate(month = ordered(month, level = c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")))
  
plot_3 = 
  sub_crime_month %>% 
  group_by(month, law_cat) %>% 
  summarise(event_num = n() / 1000) %>% 
  plot_ly(
    x = ~month, y = ~event_num, type = "scatter", mode = "points", color = ~law_cat
  )


plot_4 = 
  sub_crime_month %>% 
  group_by(month) %>% 
  summarise(event_num = n() / 1000) %>% 
  plot_ly(
    x = ~month, y = ~event_num, type = "scatter", mode = "lines"
  )

subplot = subplot(plot_4, plot_3)

layout(subplot, title = "Event number over month", xaxis = list(title = "Month"), yaxis = list(title = "Number of crime events (K)"), width = 1000)
```


## Subway Passenger


```{r read and process data, include=FALSE ,message=FALSE, warning=FALSE}
passenger_df = read_csv('data/passenger_imputed.csv', show_col_types = FALSE)

passenger_df = 
  passenger_df %>% 
  # Plotting use 1-year data 
  filter(date >= as.Date("2021-01-01"),
         date < as.Date("2021-11-05"))


# just use part of features
location_df = 
  read_csv('data/subway_info_final3.csv', show_col_types = FALSE) %>% 
  # only keep new york
  filter(administrative_area_level_1 == 'New York') %>% 
  select(station, linename, service, sublocality, postal_code, lat, long)
  

passenger_df = 
  passenger_df %>% 
  left_join(location_df, by = c('station', 'linename')) %>% 
  drop_na(sublocality) %>% 
  relocate(station, linename, service, sublocality, postal_code, lat, long)

```



### Subway passenger EDA with location


Passenger flow is closely related with crime. The more passenger flow in a station, the more criminals there will be. Therefore, we conduct EDA to:

* Find relationship between location and passenger flow
* Determine the most appropriate location variable for the model

#### Total passengers in each station

The color of each circle is the line of the subway and the size is the total number of passengers in 2021.

```{r, message=FALSE, warning=FALSE}
df = 
  passenger_df %>% 
    drop_na(entry_diff_imputed, exit_diff_imputed) %>% 
    group_by(station, service, linename, sublocality, postal_code, lat, long) %>% 
    summarise(total_entry = sum(entry_diff_imputed),
              total_exit = sum(exit_diff_imputed)) %>% 
    mutate(passenger_flow = total_entry + total_exit,
           # set passenger_flow to int
           passenger_flow = as.integer(passenger_flow))

# df %>% 
#   leaflet() %>% 
#   addTiles() %>% 
#   addCircleMarkers(~long, ~lat,radius= df$passenger_flow/100000000, weight= 0.9)


qpal <- colorQuantile("YlOrRd", df$passenger_flow, n = 4)

pal <- 
   colorFactor(palette = c("blue", "azure4", "orange",'green','green','brown','yellow','red','forestgreen','purple'), 
               levels = c('8 Avenue(ACE)',
                          'Shuttle(S)',
                          '6 Avenue(BDFM)',
                          'Brooklyn-Queens Crosstown(G)',
                          'Brooklyn-Queens(G)',
                          '14 St-Canarsie(L)',
                          'Broadway(NQRW)',
                          '7 Avenue(123)',
                          'Lexington Av(456)',
                          'Flushing(7)'))


df %>% 
  mutate(service = ifelse(service == 'Brooklyn-Queens Crosstown(G)', 'Brooklyn-Queens(G)', service)) %>% 
  mutate(passenger_flow2 = 10*log(passenger_flow)) %>% 
  leaflet() %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addCircles(lng = ~long, lat = ~lat, weight = 1, stroke = FALSE,
    radius = ~sqrt(passenger_flow)/20, popup = ~station, color = ~pal(service), opacity = 0.75, fillOpacity = 0.75) %>%
  addLegend("topright", pal = pal, values = ~service, 
            title = "Subway Service", opacity = 0.75) %>% 
  setView(-73.8399986, 40.746739, zoom = 11)
```

There are patterns between station locations and total passenger flow. Big stations are mostly located in lower and middle Manhattan, and there are some sub center stations in other areas, such as *9th Street* station in Brooklyn and *FLUSHING-MAIN* station in Queen.

#### By sublocality

```{r}
df %>% 
  ungroup %>% 
  filter('sublocality' != 'None') %>% 
  drop_na() %>% 
  group_by(sublocality) %>%  
  summarise(passenger_flow = sum(passenger_flow)) %>% 
  mutate(sublocality = as.factor(sublocality)) %>% 
  arrange(-passenger_flow) %>% 
  filter(passenger_flow < 500000 |passenger_flow > 60000000) %>% 
  knitr::kable()

```

Manhattan has the most subway passengers in 2021 and Staten Island has the least subway passenger_flow. Additionally, sublocality only has 5 levels, which is too few for a machine learning model.

#### EDA with zipcode

##### Total passengers in each zipcode


```{r, message=FALSE, warning=FALSE}
# cache zip boundaries that are download via tigris package
options(tigris_use_cache = TRUE)


# get zip boundaries that start with 282
char_zips = zctas(cb = TRUE)
char_zips = 
  char_zips %>% 
  rename(postal_code = GEOID10)

summary_df<-
  df %>%
  mutate(postal_code) %>% 
  group_by(postal_code) %>%
  summarise(passenger_flow = sum(passenger_flow),
            station_cnt = n_distinct(station, linename)) 


summary_df<-geo_join(char_zips, 
                      summary_df, 
                      by_sp = "postal_code", 
                      by_df = "postal_code",
                      how = "left") %>% 
  filter(passenger_flow>=0)

pal <- colorNumeric(
  palette = "Greens",
  domain = summary_df$passenger_flow,
  na.color = "white")

labels <- 
  paste0(
    "Zip Code: ",
    summary_df$postal_code, "<br/>",
    "Flow of Passengers: ",
    summary_df$passenger_flow) %>%
  lapply(htmltools::HTML)

# summary_df2 = 
#   char_zips %>% 
#     select(postal_code) %>% 
#     left_join(summary_df, by = 'postal_code') 

summary_df %>%  
  mutate(postal_code_int = as.integer(postal_code)) %>% 
  filter(postal_code_int >= 10000 & postal_code_int < 14900) %>% 
  leaflet() %>%
  addProviderTiles(providers$CartoDB.Positron) %>% 
   addPolygons(fillColor = ~pal(passenger_flow),
              weight = 2,
              opacity = 1,
              color = "white",
              dashArray = "3",
              fillOpacity = 0.7,
              highlight = highlightOptions(weight = 2,
                                           color = "#666",
                                           dashArray = "",
                                           fillOpacity = 0.7,
                                           bringToFront = TRUE),
              label = labels) %>% 
  addLegend(pal = pal, 
            values = ~passenger_flow, 
            opacity = 0.7, 
            title = htmltools::HTML("Total Passengers 2021"),
            position = "bottomright") %>% 
  setView(-73.8399986, 40.746739, zoom = 10)




```


##### Total subway stations in each zipcode

```{r, warning=FALSE}
labels <- 
  paste0(
    "Zip Code: ",
    summary_df$postal_code, "<br/>",
    "Stations count: ",
    summary_df$station_cnt) %>%
  lapply(htmltools::HTML)


pal <- colorNumeric(
  palette = "Purples",
  domain = summary_df$station_cnt,
  na.color = "white")

summary_df %>%  
  mutate(postal_code_int = as.integer(postal_code)) %>% 
  filter(postal_code_int >= 10000 & postal_code_int < 14900) %>% 
  leaflet() %>%
  addProviderTiles(providers$CartoDB.Positron) %>% 
   addPolygons(fillColor = ~pal(station_cnt),
              weight = 2,
              opacity = 1,
              color = "white",
              dashArray = "3",
              fillOpacity = 0.7,
              highlight = highlightOptions(weight = 2,
                                           color = "#666",
                                           dashArray = "",
                                           fillOpacity = 0.7,
                                           bringToFront = TRUE),
              label = labels) %>% 
  addLegend(pal = pal, 
            values = ~station_cnt, 
            opacity = 0.7, 
            title = htmltools::HTML("Total Stations 2021"),
            position = "bottomright") %>% 
  setView(-73.8399986, 40.746739, zoom = 10)
```

The zipcode does not demonstrate the exact relationship between location and passenger flow. For instance, some zipcodes such as *10002* and *10011* in lower Manhattan should have more passengers, however few stations are built there. Therefore, the key cause to this confusion is that subway stations are not built based on zipcode.

#### Kmeans analysis of station

We set the number of clusters to be 8 and use Kmeans to cluster latitudes and longitudes. The color of each circle is the Kmeans cluster they belong and the size is the total number of passengers in 2021.

```{r, message=FALSE, warning=FALSE}

# conduct kmeans
df_sub = 
  df %>% 
  ungroup() %>% 
  select(long, lat) %>% 
  drop_na()

k2 = kmeans(df_sub, centers = 8, nstart = 25)

# EDA with Kmeans results
df$cluster = k2$cluster

df = 
  df %>%
  mutate(cluster = case_when(
    cluster == 1 ~ 'Queen',
    cluster == 2 ~ 'Upper Manhattan',
    cluster == 3 ~ 'Queen-Brooklyn',
    cluster == 4 ~ 'Middle Manhattan',
    cluster == 5 ~ 'Bronx',
    cluster == 6 ~ 'Brooklyn',
    cluster == 7 ~ 'Lower Manhattan',
    cluster == 8 ~ 'Rockaway Beach',
  ))

pal = colorFactor(
  brewer.pal(n = 10, name = "Set1"),
  df$cluster,
  levels = NULL,
  ordered = FALSE,
  na.color = "#808080",
  alpha = FALSE,
  reverse = FALSE
)

df %>% 
  leaflet() %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addCircles(lng = ~long, lat = ~lat, weight = 1, stroke = FALSE,
    radius = ~sqrt(passenger_flow)/20, popup = ~station, color = ~pal(cluster), opacity = 1, fillOpacity = 1) %>%
  addLegend("topright", pal = pal, values = ~cluster, 
            title = "Kmeans Cluster", opacity = 1) %>% 
  setView(-73.8399986, 40.746739, zoom = 11)




```


Kmeans algorithm cluster Manhattan into three parts: lower Manhattan, middle Manhattan and upper Manhattan. Brooklyn and Queens shares 3 cluster. Also, there is a cluster for Bronx. We think the Kmeans result is easier to interpret than that of zipcode or sublocality and it can partly represent the relationship between passenger flow and location. Therefore, we use Kmeans result as the location variable in our model.




# Model

By exploratory data analysis, we found the crime was related to the victim, time and space. While producing the most precisely individual level analysis has high computation, it is relative fast and accurate for group/class analysis. Therefore, we intend to do a group analysis of crime and these independent variables. The data can be considered as a graph naturally, which represents the relations (crime) between entities (times and victims at different certain spaces). In addition, because the data graph was permutation invariant, we used graph neural networks (GNN) to solve this link prediction task.

## Methodology

Graph neural networks can extract features and make predictions about entities and relations with more information. The reader is redirected to [1] for more details. An end-to-end trainable graph auto-encoder (GAE) has shown a significantly improvement in graph-structured data for link prediction on undirected graphs [2,3]. In what follows, we implement and evaluate graph auto-encoder on our dataset.

## Experiments

#### Data Processing
 
Data sources have been mentioned earlier. In terms of time, we considered variables of date and time for events. Age, race and sex were selected as variables of victims. In the degree of space, we used service of subway lines and cluster of neighborhoods mentioned before. Considering the computing cost, we grouped subway crime data from 2006 to 2021, as shown in below. In order to transform our data into GNN acceptable, we set different (date, time) pair as item nodes and different (age, race, sex, service, cluster) vector as user nodes, and link prediction task appeared between user and item nodes. Finally, there were 1612 user nodes, 2196 item nodes and 28126 edges between them.

|         |                                               |
|---------|-----------------------------------------------|
| date    | 366 days of the year                          |
| time    | 6 time intervals with a length of 4 hours     |
| age     | 5 age groups by raw data                      |
| race    | 6 race groups by raw data                     |
| sex     | male and female                               |
| service | 8 service groups obtained by previous section |
| cluster | 8 cluster groups obtained by previous section |

#### Model selection

The data set were divided by training set, validation set (with negative sampling) and testing set (with negative sampling) with ratio 0.6, 0.2 and 0.2, respectively. After adjusting the super parameters to get better results in the validation set, we utilized two layers graph convolution neural networks and 0.5 dropout between them as encoder, which could add noise between layers to enhance the robustness of the model. The inner product was considered as the decoder. The learning rate was selected as 0.006 by validation set. After choosing binary cross entropy loss as loss function, the model has been basically established.

#### Results 

The AUC was utilized to evaluate this model. As shown in plot, although there were a little bit overfitting at the end epoch, the AUC of GAE in validation set was 0.8539. It indicated the probability that the predicted positive case is ahead of the negative case is 0.8539. Finally, in the testing set the AUC was 0.8543, which showed GAE was a classifier with good effect (>0.85).

![](images/val_auc.png){width=75%}

#### GNN to Application

In crime prediction task, we though highly of recall more than precision, because FN is more serious than FP and we wouldn’t take that risk. Therefore, we took threshold as 0.45 and predicted as positive (crime occurring) if outcome was greater than it.

# Model Application

We build the (No crime Navigation)[https://zheyanliu.shinyapps.io/NYC_subway_findroute/] APP based on [Google Maps Api](https://developers.google.com/maps) and GNN model. 

## Input parameters

In the left panel, users can select their infomation and typed in their current location and destination. This include:

* Who are you: gender, age and race
* When you leave: date and time
* Where to go: your location and destination

## Routes

When user input their infomation click on the submit button several candidates routes will be displayed in the right table. The table shows several infomation of the route including:

* time:time to get to the destination from start location
* walking distance: walking distance in this route
* crime score:the likelihood of being the victim of crime events
* crowdness score:crowdness on the route
* line[stops]:brief introduction to this route, take how many stops in each line

## Interactive route map

Users can click on each row in the routes dataframe to show the detail of this route in the map. Users can select multiple lines. 


# Summary

## Results


## Limitations


### Data limitations

The crime data is merged by two dataset, one from 2006-2020 and the other from 2021 to 2022. Although they have similar columns and both contains all the variables we interested in, the defination of crime and collection of data still have differences.

Original passenger data only contains cumulative entries and exits. When taking difference from entries and exits, the diff contains negative and unreasonably large values. We imputed the erroneous.

Another problem is that station names in the crime data and original data cannot match. We matched them based on external data source (Google Map Api). We use Api to get exact coordinates of station and category crime data to a station. Mismatch can happen in this case.

### Analysis limitations

As for the part regarding relationship between crime events and occurrence time including year, quarter, month, day of week and time points, we exploring the association between crime and events, and we show the specific relationship between the outcome of interest - crime events and variable time, for instance, which year may be the most frequent for crime events, by this, we may try to further investigate the reason for variation among years; or which time point on with day of week will be the most dangerous time for people hanging out, also by this, it may guide citizens to try to avoid these time points for outdoor activities.

### Model limitations

Considering computation cost, group analysis is relative fast and accurate. If computing power can be strengthened, the model will be stronger. In addition, due to a number of missing values, the results can be better when a 'healthier' data are given. The decoder we utilized is default,inner product, and it can be specially designed for this task.

## Acknowledgement

We would like to thank Zhuohui Liang, who gives us suggestions about this project. In addition, we want to thank team 'Police Violence and Protest' last year. Their interactive map gives us the idea of building a interactive crime map. Moreover, we would like to thank Rebekah Hughes in this team for her answering our question about Shiny Dashboard Navbar. Finally, we want to thank the [Google Map Api team](https://github.com/googlemaps/google-maps-services-python) for their open-source code and free to use api, the [No crime Navigation App](https://zheyanliu.shinyapps.io/NYC_subway_findroute/) will not be possible without their contributions. 

# Reference

[1] Daigavane, et al., "Understanding Convolutions on Graphs", Distill, 2021.

[2] Thomas N. Kipf and Max Welling. 2016. Variational Graph Auto-Encoders. NIPS Bayesian Deep Learning Workshop (2016).

[3] Berg, Rianne van den, Thomas N. Kipf, and Max Welling. "Graph convolutional matrix completion." arXiv preprint arXiv:1706.02263 (2017).






















